logging {
  level = "info"
}

livedebugging {
  enabled = true
}

// This is where we configure sending data to the grafana_cloud instances
 
// METRICS
prometheus.remote_write "metrics_service" {
  endpoint {
    url = sys.env("GC_METRIC_ENDPOINT")
 
    basic_auth {
      username = sys.env("GC_METRIC_USERNAME")
      password = sys.env("GC_METRIC_TOKEN")
    }
  }
}
 
// LOGS
loki.write "logs_service" {
  endpoint {
    url = sys.env("GC_LOG_ENDPOINT")

    basic_auth {
      username = sys.env("GC_LOG_USERNAME")
      password = sys.env("GC_LOG_TOKEN")
    }
  }
}
 
// TRACES
otelcol.exporter.otlp "grafana_cloud_tempo" {
  // https://grafana.com/docs/agent/latest/flow/reference/components/otelcol.exporter.otlp/
  client {
    endpoint = sys.env("GC_TRACE_ENDPOINT")
    auth     = otelcol.auth.basic.grafana_cloud_tempo.handler
  }
}
 
otelcol.auth.basic "grafana_cloud_tempo" {
  // https://grafana.com/docs/agent/latest/flow/reference/components/otelcol.auth.basic/
  username = sys.env("GC_TRACE_USERNAME")
  password = sys.env("GC_TRACE_TOKEN")
}

// OTEL
otelcol.receiver.otlp "default" {
  // https://grafana.com/docs/agent/latest/flow/reference/components/otelcol.receiver.otlp/

  // configures the default grpc endpoint "0.0.0.0:4317"
  grpc { }
  // configures the default http/protobuf endpoint "0.0.0.0:4318"
  http { }

  output {
    // metrics = [otelcol.processor.resourcedetection.default.input]
    metrics = [
      // otelcol.processor.batch.default.input,
    ]
    logs    = [
      // otelcol.processor.resourcedetection.default.input
    ]
    traces  = [

      // The next line generates service graph and span metrics from Alloy. By default these are
      // generated by Grafana Cloud, so be sure to configure Grafana Cloud > Application Observability > Configuration
      // to use OTEL Collector >= 0.109 / Grafana Alloy >= 1.5.0 as the span metrics source.
      // See also https://grafana.com/docs/grafana-cloud/monitor-applications/application-observability/instrument/metrics-labels/
      otelcol.processor.transform.spanmetrics.input,

      // The following would be used for tail sampling only traces containing errors.
      // Uncomment the following line, then comment out the line below it (the batch processor) to use
      // tail sampling.
      // NOTE: In this configuration, if metrics are also being generated (see above), then the order in which
      // these components are definied is not important. However, in a situation where a serial pipeline is
      //       defined, metrics generation *must* occur before tail sampling to ensure a true view of all trace
      //       requests is captured before traces are dropped by the sampler.
      //otelcol.processor.tail_sampling.errors.input,

      otelcol.processor.batch.default.input,

    ]
  }
}

// otelcol.processor.resourcedetection "default" {
//   // https://grafana.com/docs/agent/latest/flow/reference/components/otelcol.processor.resourcedetection/
//   detectors = ["env", "system"] // add "gcp", "ec2", "ecs", "elastic_beanstalk", "eks", "lambda", "azure", "aks", "consul", "heroku"  if you want to use cloud resource detection

//   system {
//     hostname_sources = ["os"]
//   }

//   output {
//     metrics = [otelcol.processor.transform.add_resource_attributes_as_metric_attributes.input]
//     logs    = [otelcol.processor.batch.default.input]
//     traces  = [
//       otelcol.processor.batch.default.input,
//       // otelcol.connector.host_info.default.input,
//     ]
//   }
// }

// otelcol.connector.host_info "default" {
//   // https://grafana.com/docs/agent/latest/flow/reference/components/otelcol.connector.host_info/
//   host_identifiers = ["host.name"]

//   output {
//     metrics = [otelcol.processor.batch.default.input]
//   }
// }

// This processor strips out all resource attributes except for the service.name attribute. This is required because
// otherwise the span metrics connector will attempt to generate separate metrics on a per-resource basis, rather than
// a per-span attribute basis (ie. multiple metrics for the same service). This will lead to clashes where
// Mimir will not be able to correctly distinguish between the metrics and therefore drop them as duplicates.
otelcol.processor.transform "spanmetrics" {
    // Ignore any errors that occur when transforming the trace data.
    error_mode = "ignore"

    // Operate only on trace data.
    trace_statements {
        // Only operate on resource attributes.
        context = "resource"

        // Only the service.name resource attribute is required by the span metrics connector for metrics generation
        // per-service, so we strip all other resource attributes.
        statements = [
            `keep_keys(attributes, ["service.name", "service.namespace", "ip"])`,
        ]
    }

    // Output to the span metrics and service graph connectors.
    output {
        traces = [
            otelcol.connector.spanmetrics.tracemetrics.input,
            otelcol.connector.servicegraph.tracemetrics.input,
        ]
    }
}

// https://grafana.com/docs/agent/latest/flow/reference/components/otelcol.connector.spanmetrics/#blocks
// https://github.com/grafana/intro-to-mltp/blob/main/alloy/config.alloy#L361
otelcol.connector.spanmetrics "tracemetrics" {

  // This will get us to traces_span_metrics_duration_seconds_[x] ie the nomenclature needed by App O11y
  namespace = "traces.span.metrics"

  dimension {
    name = "http.method"
    default = "GET"
  }

  dimension {
    name = "http.target"
  }

  dimension {
    name = "http.status_code"
  }

  dimension {
    name = "service.version"
  }

  dimension {
    name = "service.namespace"
  }

  histogram {
    unit = "s"
    explicit {
    }
  }
  
  exemplars {
    enabled = true
  }

  output {
    metrics = [otelcol.exporter.prometheus.tracemetrics.input]
    // metrics = [otelcol.processor.transform.metric_rename.input]
  }

}

// The Servicegraph Connector will generate service graph metrics (edges and nodes) based on incoming trace spans.
otelcol.connector.servicegraph "tracemetrics" {
    // Extra dimensions (metrics labels) to be added to the generated metrics from matching span attributes.
    // For this component, this is defined as an array. There are no default values and the labels will not be generated
    // for missing span attributes.
    dimensions = [
        "http.method",
        "http.target",
        "http.status_code",
        "service.version",
        "service.namespace",
    ]

    // Generated metrics data is in OTLP format. We send this data to the OpenTelemetry Prometheus exporter to ensure
    // it gets transformed into Prometheus format data.
    output {
        metrics = [otelcol.exporter.prometheus.tracemetrics.input]
    }
}

// This processor renames the span metrics names to match those that are generated by Tempo.
// otelcol.processor.transform "metric_rename" {
//     // Ignore any errors that occur when transforming the metric data
//     error_mode = "ignore"

//     // Operate only on metric statements.
//     metric_statements {
//         // Use the metric context to operate on the metric data.
//         context = "metric"
//         // Tempo generates the `traces_spanmetrics_latency_[bucket/sum/count]` metrics, but the OTel connector
//         // generates the `traces.spanmetrics.duration.[bucket/sum/count]` metrics. We need to rename the metrics
//         // to match the Tempo naming convention.
//         // We also need to rename the `traces.spanmetrics.calls` metric to `traces.spanmetrics.calls.total`, because
//         // the counter metric requires a total suffix, but we need to strip the suffix from the
//         // traces_spanmetrics_latency histogram so that our dashboards/Grafana Cloud will still operate correctly.
//         statements = [
//             `set(metric.name, "traces.spanmetrics.latency") where metric.name == "traces.spanmetrics.duration"`,
//             `set(metric.name, "traces.spanmetrics.calls.total") where metric.name == "traces.spanmetrics.calls"`,
//         ]
//     }


//     // Forward to the Prometheus exporter
//     output {
//         metrics = [otelcol.exporter.prometheus.tracemetrics.input]
//     }
// }

// otelcol.processor.transform "add_resource_attributes_as_metric_attributes" {
//   // https://grafana.com/docs/agent/latest/flow/reference/components/otelcol.processor.transform/
//   error_mode = "ignore"

//   metric_statements {
//     context    = "datapoint"
//     statements = [
//       "set(attributes[\"deployment.environment\"], resource.attributes[\"deployment.environment\"])",
//       "set(attributes[\"service.version\"], resource.attributes[\"service.version\"])",
//       "set(attributes[\"service.name\"], resource.attributes[\"service.name\"])",
//     ]
//   }

//   output {
//     metrics = [otelcol.processor.batch.default.input]
//   }
// }

otelcol.processor.batch "default" {
  // https://grafana.com/docs/agent/latest/flow/reference/components/otelcol.processor.batch/
  output {
    metrics = [otelcol.exporter.prometheus.grafana_cloud_prometheus.input]
    logs    = [otelcol.exporter.loki.grafana_cloud_loki.input]
    traces  = [otelcol.exporter.otlp.grafana_cloud_tempo.input]
  }
}

otelcol.exporter.otlphttp "grafana_cloud" {
  client {
    endpoint = sys.env("OTEL_EXPORTER_OTLP_ENDPOINT")
    auth = otelcol.auth.basic.grafana_cloud.handler
  }
}

otelcol.auth.basic "grafana_cloud" {
  username = sys.env("GC_OTEL_USERNAME")
  password = sys.env("GC_OTEL_TOKEN")
}

// These forward to our existing defined logs and metrics services
otelcol.exporter.loki "grafana_cloud_loki" {
  // https://grafana.com/docs/agent/latest/flow/reference/components/otelcol.exporter.loki/
  forward_to = [loki.write.logs_service.receiver]
}

otelcol.exporter.prometheus "tracemetrics" {
    // We don't want to add the `_total` suffix to the metrics, because we've already renamed the
    // `traces.spanmetrics.calls` metric to `traces.spanmetrics.calls.total`, and we don't want to add the
    // `_milliseconds` suffix to the `traces.spanmetrics.latency` metric.
    // we do however want to add _seconds suffix to the histogram metrics
    add_metric_suffixes = true
    forward_to          = [prometheus.remote_write.metrics_service.receiver]
}

otelcol.exporter.prometheus "grafana_cloud_prometheus" {
  // https://grafana.com/docs/agent/latest/flow/reference/components/otelcol.exporter.prometheus/
  // add_metric_suffixes = false
  forward_to          = [prometheus.remote_write.metrics_service.receiver]
}